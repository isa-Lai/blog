[{"content":"Finite State Machine AKA coherence controller.\nCoherence Protocols Specifing Protocols State: For example, Not readable or writable (N), Read-only (RO), Read-write (RW). These is the state of the cache. Events: For example, Load, Store, Incoming Coherence request to optain read-write state. Transitions: Actions Load Store Incoming Coherence request to optain read-write state N Issue request to get RO Issue request to get RW NA RO Give data Issue request to get RW NA/N RW Give data Write data Send Block to requestor/N States Implemented ststes shoudl consider:\nValidity: Has the up-to-date value. Can read, but can write if it is also exclusive. Dirtiness: Write to up-to-date, but not yet push to lower memory. Exclusivity: No other private cache has a copy of the block. Ownership: Owner is responsible for responding to coherence reqeust for that block. MOESI/MSI Modified: Valid, exclusive, owned, and maybe dirty. Can read and write. Owned: Valid, and owned, and maybe dirty. Read-only. Other core also have read-only copy but not owners. Exclusive: Valid, exclusive, and clean. Read-only. Shared: Valid and clean. Read-only. Invalid: Invalid. Transiten States States that is inbetween two states. ie., $IV^D$ (in Invalid going to Valid, waiting for DataResq).\nTransactions Transaction Goal of Requestor GetShared (GetS) Obtain block in Shared (read-only) state GetModified (GetM) Obtain block in Modified (read-write) state Upgrade (Upg) Upgrade block state from read-only (Shared or Owned) to read-write (Modified); Upg (unlike GetM) does not require data to be sent to requestor PutShared (PutS) Evict block in Shared state* PutExclusive (PutE) Evict block in Exclusive state* PutOwned (PutO) Evict block in Owned state PutModified (PutM) Evict block in Modified state *Some protocols do not require a coherence transaction to evict a Shared block and/or an Exclusive block (i.e., the PutS and/or PutE are \u0026ldquo;silent\u0026rdquo;).\nEvent Response of (Typical) Cache Controller Load If cache hit, respond with data from cache; else initiate GetS transaction Store If cache hit in state E or M, write data into cache; else initiate GetM or Upg transaction Atomic read-modify-write If cache hit in state E or M, atomically execute RMW semantics; else GetM or Upg transaction Instruction fetch If cache hit (in I-cache), respond with instruction from cache; else initiate GetS transaction Read-only prefetch If cache hit, ignore; else may optionally initiate GetS transaction* Read-Write prefetch If cache hit in state M, ignore; else may optionally initiate GetM or Upg transaction* Replacement Depending on state of block, initiate PutS, PutE, PutO, or PutM transaction *A cache controller may choose to ignore a prefetch request from the core.\nMajor Protocal Design Options Directory vs. Snooping\nDirectory protocol: A directory is used to track the state of each block. Cache controller send request to the home of that block. Snooping protocol: A shared bus is used to broadcast the state of each block. Assume requests arrive in totol order. Invalidate vs. Update\nInvalidate protocol: Write will invalidate the block, so other core cannot read. Update protocol: Write update all copies of the block. Snooping Protocol Usually using a bus to broadcast the requests, but not necessarily has to use a bus.\nSIMPLE SNOOPING SYSTEM MODEL: ATOMIC REQUESTS, ATOMIC TRANSACTIONS Simple snooping for cache controller, labeled “(A)” denotes that this transition is impossible because transactions are atomic on bus:\nStates Processor Core Events Bus Events Own Transaction Other Transaction Load Store Replacement Own-GetS Own-GetM Own-PutM Data Other-GetS Other-GetM Other-PutM I Issue GetS /ISD Issue GetM /IMD ISD Stall Load Stall Store Stall Evict Copy data into cache, load hit /S (A) (A) (A) IMD Stall Load Stall Store Stall Evict Copy data into cache, store hit /M (A) (A) (A) S Load hit Issue GetM /SMD - /I - /I SMD Load hit Stall Store Stall Evict Copy data into cache, store hit /M (A) (A) (A) M Load hit Store hit Issue PutM, send Data to memory /I Send Data to req and memory /S Send Data to req /I Atomic request: Issue request ensures that another core\u0026rsquo;s request will not ordered ahead of its, when this cache controller seeks to upgrade permission (I-\u0026gt;S, S-\u0026gt;M, or I-\u0026gt;M). Thus, controller transition immediately to state $IS^D$, $IM^D$, or $SM^D$. Atomic transaction: No subsequent requests from a block will occur until the current transaction completes. Resquest always comes with reponse in pair. BASELINE SNOOPING SYSTEM MODEL: NON-ATOMIC REQUESTS, ATOMIC TRANSACTIONS\nMESI Rely on atomic transactions. Use E instead of S: when GetS occurs when no other cache has access to the block. Upgrade from E to M is silent. No transactions needed. Elinimate half of the transactions. Note: in the figure when it says, \u0026ldquo;mem in I\u0026rdquo;, it means in the lower level memory (ie,. LLC or DRAM), that cache block is in I which states that no private cache has a copy of that block. It does not mean the cache in the private cache is in I state.\nMOSI Rely on atomic transactions. Eliminate extra data to update LLC when a cache receives a GetS request in the M/E state. Using dirty bit, eliminate unnecessary write to LLC (if block is written again before write back to LLC). Owner is used to reduce the access latency. Without owner, even a core\u0026rsquo;s private has a copy in S, it cannot forward the copy to other because no one know who is the owner. Only the defined owner can forward the copy. Non-atomic bus Send request without waiting for previous response. Pipelined bus: response in same order as request. Split transaction bus: response in random order depending on latency. 1 2 3 4 5 6 7 8 9 10 11 Atomic bus: Address Bus: Request 1 ----------- Request 2 ------------ Request 3 Data Bus: Response 1 ----------- Response 2 ----------- Response 3 Pipelined (non-atomic) bus: Address Bus: Request 1 Request 2 Request 3 Data Bus: Response 1 Response 2 Response 3 Split transaction (non-atomic) bus: Address Bus: Request 1 Request 2 Request 3 Data Bus: Response 2 Response 3 Response 1 non-atomic system model: can use FIFO queue to buffer messages. Directory Protocol Directory: a global view of the coherence state of each block. Forwarding, the directory controller can forward the request to the owner of the block. A directory entry can be like (N: number of nodes):\nstate owner starer list (one-host bit vector) 2-bit $Log_2(N)$-bit $N$-bit Avoiding Deadlocks Deadlock: Event A causes event B and both require resource allocation. Deadlock can occur when the resources are both not available until one of the event completes. For example, GetS can causes Fwd-GetS which uses the same resources. 1 2 3 4 5 6 7 8 Full | Queue | ------\u0026gt; C1 -----\u0026gt; ^ | | | | | | | -----C2\u0026lt;--------------| Queue | Full To avoid deadlock, we can use different netwroks for different calss of messages. This avoid dependence between different messages. ie,. response and request.\nDetailed Protocal Specification MSI Directory Protocol - directory controller\nGetS GetM PutS-NotLast PutS-Last Put M+data from Owner PutM+data from Non-Owner Data I Send data to Req, add Req to Sharers/S Send data to Req, set Owner to Req/M Send Put-Ack to Req Send Put-Ack to Req Send Put-Ack to Req S Send data to Req, add Req to Sharers Send data to Req, send Inv to Sharers, clear Sharers, set Owner to Req/M Remove Req from Sharers, sent Put-Ack to Req Remove Req from Sharers, send Put-Ack to Req/I Remove Req from Sharers, send Put-Ack to Req M Send Fwd-GetS to Owner, add Req and Owner to Sharers, clear Owner/SD Send Fwd-GetM to Owner, set Owner to Req Send Put-Ack to Req Send Put-Ack to Req Copy data to memory, clear Owner, send Put-Ack to Req/I Send Put-Ack to Req SD Stall Stall Remove Req from Sharers, send Put-Ack to Req Remove Req from Sharers, send Put-Ack to Req Remove Req from Sharers, send Put-Ack to Req Copy data to memory/S References Sorin, D. J., Hill, M. D., Wood, D. A., \u0026amp; Nagarajan, V. (2020). A primer on memory consistency and cache coherence (2nd ed., pp. 91-191). Springer Nature. https://doi.org/10.1007/978-3-031-01764-3\n","date":"2024-10-09T14:00:00Z","image":"https://isa-lai.com/blog/cache/cache-coherence-controller.png","permalink":"https://isa-lai.com/blog/p/cache-coherence-3-coherence-protocols/","title":"Cache Coherence (3) - Coherence Protocols"},{"content":"Problem is Shared Memory For these intructions in two cores:\nCore C1 Core C2 * S1: x = 1 S2: y = 1 x and y initialy be 0 L1: r1 = y L2: r2 = x We could get different results depending on the order of execution:\nr1 r2 Execution Order 0 1 S1 L1 S2 L2 1 0 S2 L2 S1 L1 1 1 S1 S2 L1 L2 0 0 *Possibly when using FIFO write buffers. Consistency vs Coherence? Cache coherence does not equal memory consistency. Coherence simply provide a pipelined way to update the cache. It along does not determine shared memory behavior. A memory consistency implementation can use cache coherence as a useful “black box.” Sequential Consistency (SC) Most intuitive memory model. Basic idea:\nSingle processor sequential: result like executed in order. Multi-processor sequential: single core in the sequence of in order, while all core also execute in some sequential order. The total order of operations is memory order, like this figure: Here is a example SC execution for the preious sample table of execution S1 S2 L1 L2.\nSC Execution Reqires the following (L(a) and S(a) represent a load and a store, respectively, to address a, Orders \u0026lt;p and \u0026lt;m define program and global memory order.):\nAll cores insert request to \u0026lt;m respecting to their programe order. Four cases: If L(a) \u0026lt;p L(b) -\u0026gt; L(a) \u0026lt;m L(b) /* Load-\u0026gt;Load */ If L(a) \u0026lt;p S(b) -\u0026gt; L(a) \u0026lt;m S(b) /* Load-\u0026gt;Store */ If S(a) \u0026lt;p S(b) -\u0026gt; S(a) \u0026lt;m S(b) /* Store-\u0026gt;Store */ If S(a) \u0026lt;p L(b) -\u0026gt; S(a) \u0026lt;m L(b) /* Store-\u0026gt;Load */ Every load gets the value from the latest store in memory order. SC implementation 2 Native implementation:\nMultistasking Uniprocessor Multi threading in single processor. T1 executes on C1 until context switch to T2 On a context switch, all pending memory requests must complete before switching. Switch Pick a core, complete one request, and then switch to next core. Can be random, round-robin, or any other scheme that does not starve a core. SC Implementation with Cache Coherence Conflict: two operations to the same address in parallel, and at least one writes.\nHere assume SWMR(Single Writer Multi Reader)\nState Machine:\nM: modified - read and write permit S: shared - read permit GetM and GetS: coherence requests to obtain a block in M or S. Requests can perform in parallel is no conflict. Optimizing SC Implementation Non-Binding Prefetching Speculative Cores: When branch prediction squashes intructions, the non-binding prefetching does not get squashed. Dynamically Scheduled Cores: out-of-order execution. Multithreading Atomic operations with SC Atomically perform paris of operations for thread synchronization. Read-Modify-Write (RMW) aka:\nLoad-Linked/Store-Conditional (LL/SC) Test-and-Set (TS) Compare-and-Swap (CAS) Fetch-and-Add (FAA) RMW atomically read to check if it is unlocked, and write the locked value. To be atomic, read and write must appear consecutively.\nAtomic RMW does not need to inform other cores.\nThe core obtain the block in M in its cache. If block is not M or not there, just load and store the block in its cache. Serve any incoming coherence requests intil it stores. TSO/X86 Motivation write buffer hold the committed store until it retire and write to cache/register. More performance improvement can be done by forward/bypass the latest store to load.\nBack to the example:\nCore C1 Core C2 * S1: x = 1 S2: y = 1 x and y initialy be 0 L1: r1 = y L2: r2 = x C1 run S1, and buffer NEW to write buffer C2 run S2, and buffer NEW to write buffer Both run L1 and L2, which both get 0 from memory Finally both write buffers update x and y to NEW TSO compare to SC SC execution is a subset of TSO execution.\nStore-\u0026gt;Load in program order not necessary be the same in memory order, so SC has this but TSO does not:\nIf S(a) \u0026lt;p L(b) -\u0026gt; S(a) \u0026lt;m L(b) /* Store-\u0026gt;Load */ Programmer/Compiler can prevent this by using FENCE instruction. Memory operation before FENCE must complete before any memory operation after FENCE.\nBypassing Most bypassing value can only be within its own thread.\nAtomic Load of RMW cannot pass an earlier store because of this wrong scenario:\nLoad of RMW pass earlier store. Store of RMW pass earlier store because they are atomic pare. Store passing store is illegal in TSO. To fix this:\nRMW effectively drains/runs the write buffer before it can perform the load. Load part need read-write coherence permission. Cannot change/relinquish permission in the middle of RMW. Relaxed Memory Consistency Can reorder any memory operation unless there is a FENCE. Requires programmer to explicitly mark the FENCE. Some advantages:\nNon-FIFO Coalescing Write Buffer Simpler Implementation Coupling consistency and coherence: Relaxed Model opens the coherence box. eXample relaxed Consistency model (XC) XC gratrnteed to preserve program order for:\nLoad/Store -\u0026gt; FENCE FENCE -\u0026gt; FENCE FENCE -\u0026gt; Load/Store XC keeps TSO rules for two same address access:\nLoad -\u0026gt; Load/Store Store -\u0026gt; Store For example for this case, we have to insert FENCE at these places to get r2 = 1:\nCore C1 Core C2 * S1: x = 1 F1: FENCE S2: y = 1 L1: r1 = x B1: if (r1≠ 1) goto L1; F2: FENCE L2: r2 = y Implementation Each core has a Reorder Buffer (ROB) to reorder load and store. Reorder based on RC rules. FENCE: FENCH as drain: costly but common. FENCH as no-ops: not in commercial product yet. Atomic The same as TSO: drain the write buffer before performing RMW. However, XC needs a FENCH for RMW or lock release.\nFor examples:\nNote XC Inst Read L and hold L if L is 0 RMW: L If L==1, goto RMW; FENCE Critical Sections Memory Requests Release Lock FENCE; Store L=0 Data Races Assume acquire lock and release lock always has FENCH to perform the correct mutual exclusion.\nIn this case, r1 and r2 can be any combination of 0 and 1. There is a data race.\nCore C1 Core C2 * lock S1: x = 1 L1: r1 = y x and y initialy be 0 S2: y = 1 L2: r2 = x unlock Now, r1 and r2 can only be (0,0) or (1,1). There is no data race.\nCore C1 Core C2 * lock lock S1: x = 1 L1: r1 = y x and y initialy be 0 S2: y = 1 L2: r2 = x unlock unlock References Sorin, D. J., Hill, M. D., Wood, D. A., \u0026amp; Nagarajan, V. (2020). A primer on memory consistency and cache coherence (2nd ed., pp. 17-90). Springer Nature. https://doi.org/10.1007/978-3-031-01764-3\n","date":"2024-10-08T19:31:55-04:00","image":"https://isa-lai.com/blog/cache/sequential-consistency.png","permalink":"https://isa-lai.com/blog/p/cache-coherence-2-memory-consistency/","title":"Cache Coherence (2) - Memory Consistency"},{"content":"What is Consistency? Consistency (a.k.a., memory consistency or memory model) is a property of a system that ensures all cache entries are consistent with the main memory. In other words, it is the process of ensuring that all copies of a memory location are updated to reflect the same value.\nWhat is Coherence? Coherence (a.k.a., cache coherence) is a mechanism to support consistency models in systems with caches.\nHow Incoherence Happens A core is updating a cache line in its own cache, while this write is not yet propagated to other cores\u0026rsquo; caches.\nFor example in this figure, assuming that A is 42 in main memory and all cores\u0026rsquo; local caches. Core C1 updates the cache line with A = 43. However, this update has not been propagated to cores C2 yet, so C2\u0026rsquo;s A will be stale value 42, and tracked in loop forever.\nCoherence Interface Consistency-agnostic coherence Write is visible to other cores immediately before returning. Synchronously. Assume it is interacting with an atomic memory system with no caches present. Like cache is movoed and only memory is contained within the coherence box, like this figure. Coherence Invariants Single-writer–multiple-reader (SWMR): At one moment, at one location: One core can wrire and read. Other cores can only read. Data-value invariant: The value at the start of an epoch is the same as that at the end of its last read-write epoch. epoch: a block of time when a core is reading or writing. Maintaining Invarients: When read: Check if other cores have read-write state. Send message to end any read-write state. When write: Send message to let other cores to obtains current value. Message ends any read-write or read-only, and new next read-write. Consistency-directed coherence Write can be visible to other cores after returning. Asynchronously. Need conherence protocol to ensure the order of writes. References Sorin, D. J., Hill, M. D., Wood, D. A., \u0026amp; Nagarajan, V. (2020). A primer on memory consistency and cache coherence (2nd ed., pp. 1-16). Springer Nature. https://doi.org/10.1007/978-3-031-01764-3\n","date":"2024-10-07T07:50:47-04:00","image":"https://isa-lai.com/blog/cache/pipeline-coherence-interface.png","permalink":"https://isa-lai.com/blog/p/cache-coherence-1-introduction/","title":"Cache Coherence (1) - Introduction"},{"content":"Welcome to Isa\u0026rsquo;s Blog!\nThis is a blog about Isa\u0026rsquo;s learning and experience in the field of software engineering, compiler, and computer architecture.\nCheck out my profile for more information about me.\n","date":"2024-10-06T00:00:00Z","image":"https://isa-lai.com/blog/p/welcome/cover_hu6307248181568134095.jpg","permalink":"https://isa-lai.com/blog/p/welcome/","title":"Welcome"}]