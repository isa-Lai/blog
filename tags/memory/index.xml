<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Memory on Isa Lai | Blog</title><link>https://isa-lai.com/blog/tags/memory/</link><description>Recent content in Memory on Isa Lai | Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 08 Oct 2024 19:31:55 -0400</lastBuildDate><atom:link href="https://isa-lai.com/blog/tags/memory/index.xml" rel="self" type="application/rss+xml"/><item><title>Cache Coherence (2) - Memory Consistency</title><link>https://isa-lai.com/blog/p/cache-coherence-2-memory-consistency/</link><pubDate>Tue, 08 Oct 2024 19:31:55 -0400</pubDate><guid>https://isa-lai.com/blog/p/cache-coherence-2-memory-consistency/</guid><description>&lt;img src="https://isa-lai.com/blog/cache/sequential-consistency.png" alt="Featured image of post Cache Coherence (2) - Memory Consistency" />&lt;h2 id="problem-is-shared-memory">Problem is Shared Memory
&lt;/h2>&lt;p>For these intructions in two cores:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">Core C1&lt;/th>
&lt;th style="text-align: center">Core C2&lt;/th>
&lt;th style="text-align: center">*&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">S1: x = 1&lt;/td>
&lt;td style="text-align: center">S2: y = 1&lt;/td>
&lt;td style="text-align: center">x and y initialy be 0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">L1: r1 = y&lt;/td>
&lt;td style="text-align: center">L2: r2 = x&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>We could get different results depending on the order of execution:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">r1&lt;/th>
&lt;th style="text-align: center">r2&lt;/th>
&lt;th style="text-align: center">Execution Order&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">0&lt;/td>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">S1 L1 S2 L2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">0&lt;/td>
&lt;td style="text-align: center">S2 L2 S1 L1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">1&lt;/td>
&lt;td style="text-align: center">S1 S2 L1 L2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">0&lt;/td>
&lt;td style="text-align: center">0&lt;/td>
&lt;td style="text-align: center">*Possibly when using FIFO write buffers.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="consistency-vs-coherence">Consistency vs Coherence?
&lt;/h2>&lt;ul>
&lt;li>Cache coherence does not equal memory consistency. Coherence simply provide a pipelined way to update the cache. It along does not determine shared memory behavior.&lt;/li>
&lt;li>A memory consistency implementation can use cache coherence as a useful “black box.”&lt;/li>
&lt;/ul>
&lt;h2 id="sequential-consistency-sc">Sequential Consistency (SC)
&lt;/h2>&lt;p>Most intuitive memory model. Basic idea:&lt;/p>
&lt;ul>
&lt;li>Single processor sequential: result like executed in order.&lt;/li>
&lt;li>Multi-processor sequential: single core in the sequence of in order, while all core also execute in some sequential order. The total order of operations is &lt;code>memory order&lt;/code>, like this figure:&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://isa-lai.com/blog/blog/cache/sequential-consistency.png"
loading="lazy"
alt="Sequential Consistency"
>&lt;/p>
&lt;p>Here is a example SC execution for the preious sample table of execution S1 S2 L1 L2.&lt;/p>
&lt;p>&lt;img src="https://isa-lai.com/blog/blog/cache/sc-example.png"
loading="lazy"
alt="Sequential Consistency Example"
>&lt;/p>
&lt;h3 id="sc-execution">SC Execution
&lt;/h3>&lt;p>Reqires the following (L(a) and S(a) represent a load and a store, respectively, to address &lt;code>a&lt;/code>, Orders &amp;lt;p and &amp;lt;m define program and global memory order.):&lt;/p>
&lt;ul>
&lt;li>All cores insert request to &amp;lt;m respecting to their programe order. Four cases:
&lt;ul>
&lt;li>If L(a) &amp;lt;p L(b) -&amp;gt; L(a) &amp;lt;m L(b) /* Load-&amp;gt;Load */&lt;/li>
&lt;li>If L(a) &amp;lt;p S(b) -&amp;gt; L(a) &amp;lt;m S(b) /* Load-&amp;gt;Store */&lt;/li>
&lt;li>If S(a) &amp;lt;p S(b) -&amp;gt; S(a) &amp;lt;m S(b) /* Store-&amp;gt;Store */&lt;/li>
&lt;li>If S(a) &amp;lt;p L(b) -&amp;gt; S(a) &amp;lt;m L(b) /* Store-&amp;gt;Load */&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Every load gets the value from the latest store in memory order.&lt;/li>
&lt;/ul>
&lt;h3 id="sc-implementation">SC implementation
&lt;/h3>&lt;p>2 Native implementation:&lt;/p>
&lt;ul>
&lt;li>Multistasking Uniprocessor
&lt;ul>
&lt;li>Multi threading in single processor.
&lt;ul>
&lt;li>T1 executes on C1 until context switch to T2&lt;/li>
&lt;li>On a context switch, all pending memory requests must complete before switching.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Switch
&lt;ul>
&lt;li>Pick a core, complete one request, and then switch to next core.&lt;/li>
&lt;li>Can be random, round-robin, or any other scheme that does not starve a core.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="sc-implementation-with-cache-coherence">SC Implementation with Cache Coherence
&lt;/h4>&lt;p>&lt;code>Conflict&lt;/code>: two operations to the same address in parallel, and at least one writes.&lt;/p>
&lt;p>Here assume SWMR(Single Writer Multi Reader)&lt;/p>
&lt;p>State Machine:&lt;/p>
&lt;ul>
&lt;li>M: modified - read and write permit&lt;/li>
&lt;li>S: shared - read permit&lt;/li>
&lt;li>GetM and GetS: coherence requests to obtain a block in M or S.&lt;/li>
&lt;li>Requests can perform in parallel is no conflict.&lt;/li>
&lt;/ul>
&lt;h4 id="optimizing-sc-implementation">Optimizing SC Implementation
&lt;/h4>&lt;ul>
&lt;li>Non-Binding Prefetching&lt;/li>
&lt;li>Speculative Cores: When branch prediction squashes intructions, the non-binding prefetching does not get squashed.&lt;/li>
&lt;li>Dynamically Scheduled Cores: out-of-order execution.&lt;/li>
&lt;li>Multithreading&lt;/li>
&lt;/ul>
&lt;h3 id="atomic-operations-with-sc">Atomic operations with SC
&lt;/h3>&lt;p>Atomically perform paris of operations for &lt;code>thread synchronization&lt;/code>. &lt;strong>Read-Modify-Write&lt;/strong> (RMW) aka:&lt;/p>
&lt;ul>
&lt;li>Load-Linked/Store-Conditional (LL/SC)&lt;/li>
&lt;li>Test-and-Set (TS)&lt;/li>
&lt;li>Compare-and-Swap (CAS)&lt;/li>
&lt;li>Fetch-and-Add (FAA)&lt;/li>
&lt;/ul>
&lt;p>RMW atomically read to check if it is unlocked, and write the locked value. To be atomic, read and write must appear consecutively.&lt;/p>
&lt;p>Atomic RMW does not need to inform other cores.&lt;/p>
&lt;ol>
&lt;li>The core obtain the block in M in its cache.&lt;/li>
&lt;li>If block is not M or not there, just load and store the block in its cache.&lt;/li>
&lt;li>Serve any incoming coherence requests intil it stores.&lt;/li>
&lt;/ol>
&lt;h2 id="tsox86">TSO/X86
&lt;/h2>&lt;h3 id="motivation">Motivation
&lt;/h3>&lt;p>&lt;code>write buffer&lt;/code> hold the committed store until it retire and write to cache/register. More performance improvement can be done by &lt;em>forward/bypass&lt;/em> the latest store to load.&lt;/p>
&lt;p>Back to the example:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">Core C1&lt;/th>
&lt;th style="text-align: center">Core C2&lt;/th>
&lt;th style="text-align: center">*&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">S1: x = 1&lt;/td>
&lt;td style="text-align: center">S2: y = 1&lt;/td>
&lt;td style="text-align: center">x and y initialy be 0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">L1: r1 = y&lt;/td>
&lt;td style="text-align: center">L2: r2 = x&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>C1 run S1, and buffer NEW to write buffer&lt;/li>
&lt;li>C2 run S2, and buffer NEW to write buffer&lt;/li>
&lt;li>Both run L1 and L2, which both get 0 from memory&lt;/li>
&lt;li>Finally both write buffers update x and y to NEW&lt;/li>
&lt;/ul>
&lt;h3 id="tso-compare-to-sc">TSO compare to SC
&lt;/h3>&lt;p>SC execution is a subset of TSO execution.&lt;/p>
&lt;p>Store-&amp;gt;Load in program order not necessary be the same in memory order, so SC has this but TSO does not:&lt;/p>
&lt;ul>
&lt;li>If S(a) &amp;lt;p L(b) -&amp;gt; S(a) &amp;lt;m L(b) /* Store-&amp;gt;Load */&lt;/li>
&lt;/ul>
&lt;p>Programmer/Compiler can prevent this by using &lt;code>FENCE&lt;/code> instruction. Memory operation before FENCE must complete before any memory operation after FENCE.&lt;/p>
&lt;h3 id="bypassing">Bypassing
&lt;/h3>&lt;p>Most bypassing value can only be within its own thread.&lt;/p>
&lt;h3 id="atomic">Atomic
&lt;/h3>&lt;p>Load of RMW cannot pass an earlier store because of this wrong scenario:&lt;/p>
&lt;ul>
&lt;li>Load of RMW pass earlier store.&lt;/li>
&lt;li>Store of RMW pass earlier store because they are atomic pare.&lt;/li>
&lt;li>Store passing store is illegal in TSO.&lt;/li>
&lt;/ul>
&lt;p>To fix this:&lt;/p>
&lt;ul>
&lt;li>RMW effectively drains/runs the write buffer before it can perform the load.&lt;/li>
&lt;li>Load part need read-write coherence permission.&lt;/li>
&lt;li>Cannot change/relinquish permission in the middle of RMW.&lt;/li>
&lt;/ul>
&lt;h2 id="relaxed-memory-consistency">Relaxed Memory Consistency
&lt;/h2>&lt;ul>
&lt;li>Can reorder any memory operation unless there is a FENCE.&lt;/li>
&lt;li>Requires programmer to explicitly mark the FENCE.&lt;/li>
&lt;/ul>
&lt;p>Some advantages:&lt;/p>
&lt;ul>
&lt;li>Non-FIFO Coalescing Write Buffer&lt;/li>
&lt;li>Simpler Implementation&lt;/li>
&lt;li>Coupling consistency and coherence: Relaxed Model &lt;em>opens the coherence box&lt;/em>.&lt;/li>
&lt;/ul>
&lt;h3 id="example-relaxed-consistency-model-xc">eXample relaxed Consistency model (XC)
&lt;/h3>&lt;p>XC gratrnteed to preserve program order for:&lt;/p>
&lt;ul>
&lt;li>Load/Store -&amp;gt; FENCE&lt;/li>
&lt;li>FENCE -&amp;gt; FENCE&lt;/li>
&lt;li>FENCE -&amp;gt; Load/Store&lt;/li>
&lt;/ul>
&lt;p>XC keeps TSO rules for two same address access:&lt;/p>
&lt;ul>
&lt;li>Load -&amp;gt; Load/Store&lt;/li>
&lt;li>Store -&amp;gt; Store&lt;/li>
&lt;/ul>
&lt;p>For example for this case, we have to insert FENCE at these places to get r2 = 1:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">Core C1&lt;/th>
&lt;th style="text-align: center">Core C2&lt;/th>
&lt;th style="text-align: center">*&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">S1: x = 1&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">&lt;strong>F1: FENCE&lt;/strong>&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">S2: y = 1&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">L1: r1 = x&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">B1: if (r1≠ 1) goto L1;&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;strong>F2: FENCE&lt;/strong>&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">L2: r2 = y&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="implementation">Implementation
&lt;/h3>&lt;ul>
&lt;li>Each core has a &lt;strong>Reorder Buffer (ROB)&lt;/strong> to reorder load and store.&lt;/li>
&lt;li>Reorder based on RC rules.&lt;/li>
&lt;li>FENCE:
&lt;ol>
&lt;li>FENCH as drain: costly but common.&lt;/li>
&lt;li>FENCH as no-ops: not in commercial product yet.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h3 id="atomic-1">Atomic
&lt;/h3>&lt;p>The same as TSO: drain the write buffer before performing RMW. However, XC needs a FENCH for RMW or lock release.&lt;/p>
&lt;p>For examples:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">Note&lt;/th>
&lt;th style="text-align: left">XC Inst&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">Read L and hold L if L is 0&lt;/td>
&lt;td style="text-align: left">RMW: L If L==1, goto RMW; &lt;strong>FENCE&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Critical Sections&lt;/td>
&lt;td style="text-align: left">Memory Requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">Release Lock&lt;/td>
&lt;td style="text-align: left">&lt;strong>FENCE&lt;/strong>; Store L=0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="data-races">Data Races
&lt;/h3>&lt;p>Assume acquire lock and release lock always has FENCH to perform the correct mutual exclusion.&lt;/p>
&lt;p>In this case, r1 and r2 can be any combination of 0 and 1. There is a data race.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">Core C1&lt;/th>
&lt;th style="text-align: center">Core C2&lt;/th>
&lt;th style="text-align: center">*&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">lock&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">S1: x = 1&lt;/td>
&lt;td style="text-align: center">L1: r1 = y&lt;/td>
&lt;td style="text-align: center">x and y initialy be 0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">S2: y = 1&lt;/td>
&lt;td style="text-align: center">L2: r2 = x&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">unlock&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Now, r1 and r2 can only be (0,0) or (1,1). There is no data race.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: center">Core C1&lt;/th>
&lt;th style="text-align: center">Core C2&lt;/th>
&lt;th style="text-align: center">*&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: center">lock&lt;/td>
&lt;td style="text-align: center">lock&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">S1: x = 1&lt;/td>
&lt;td style="text-align: center">L1: r1 = y&lt;/td>
&lt;td style="text-align: center">x and y initialy be 0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">S2: y = 1&lt;/td>
&lt;td style="text-align: center">L2: r2 = x&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: center">unlock&lt;/td>
&lt;td style="text-align: center">unlock&lt;/td>
&lt;td style="text-align: center">&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="references">References
&lt;/h2>&lt;p>Sorin, D. J., Hill, M. D., Wood, D. A., &amp;amp; Nagarajan, V. (2020). &lt;em>A primer on memory consistency and cache coherence&lt;/em> (2nd ed., pp. 17-90). Springer Nature. &lt;a class="link" href="https://doi.org/10.1007/978-3-031-01764-3" target="_blank" rel="noopener"
>https://doi.org/10.1007/978-3-031-01764-3&lt;/a>&lt;/p></description></item></channel></rss>